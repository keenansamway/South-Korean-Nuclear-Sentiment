{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "DATA_DIR = Path.cwd() / 'data'\n",
    "MODEL_DIR = Path.cwd() / 'models'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stats:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.count = 0\n",
    "        self.loss = 0\n",
    "        self.correct = 0\n",
    "        \n",
    "    def update(self, loss, correct):\n",
    "        self.count += 1\n",
    "        self.loss += loss\n",
    "        self.correct += correct\n",
    "    \n",
    "    def avg_loss(self):\n",
    "        return self.loss / self.count\n",
    "    \n",
    "    def avg_acc(self):\n",
    "        return self.correct / (self.count * self.batch_size)\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, learning_rate, batch_size, vocab_size, embedding_dim, rnn_size, out_size, rnn_num_layers, bidirectional=False, batch_first=True, dropout=0.0, num_workers=0):\n",
    "        self.lr = learning_rate\n",
    "        self.dropout = dropout\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.rnn_size = rnn_size\n",
    "        self.out_size = out_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.batch_first = batch_first"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.x = self.df['text'].to_numpy()\n",
    "        self.y = self.df['pro_nuclear'].to_numpy()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "\n",
    "class MyCollate:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        texts = [item[0] for item in batch]\n",
    "        targets = [item[1] for item in batch]\n",
    "        \n",
    "        texts = self.tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            # truncation=True,\n",
    "            # max_length=128,\n",
    "            return_tensors='pt',\n",
    "        ).input_ids\n",
    "        \n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        \n",
    "        return texts, targets\n",
    "\n",
    "\n",
    "def get_loader(df, tokenizer, config=None, batch_size=8, num_workers=0, suffle=True, pin_memory=True):\n",
    "    if config is not None: \n",
    "        batch_size = config.batch_size\n",
    "        num_workers = config.num_workers\n",
    "    \n",
    "    dataset = TextDataset(df)\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=suffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        collate_fn=MyCollate(tokenizer=tokenizer),\n",
    "    )\n",
    "    \n",
    "    return loader, dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.embedding_dim)\n",
    "                \n",
    "        self.lstm = nn.LSTM(\n",
    "            config.embedding_dim,\n",
    "            config.rnn_size,\n",
    "            num_layers=config.rnn_num_layers,\n",
    "            # bidirectional=config.bidirectional,\n",
    "            batch_first=config.batch_first,\n",
    "            dropout=config.dropout,\n",
    "        )\n",
    "        \n",
    "        # if config.bidirectional:\n",
    "        #     self.fc = nn.Linear(config.rnn_size * 2, config.out_size)\n",
    "        # else:\n",
    "        self.fc = nn.Linear(config.rnn_size, config.out_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        logits, hidden = self.lstm(embedded)\n",
    "        logits = self.dropout(logits)\n",
    "        logits = logits[:,-1,:]\n",
    "        out = self.fc(logits)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, criterion, train_loader, val_loader, batch_size):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def save_checkpoint(self, filename='checkpoint.pt', directory=MODEL_DIR):\n",
    "        torch.save(self.model.state_dict(), directory / filename)\n",
    "    \n",
    "    def load_checkpoint(self, filename='checkpoint.pt', directory=MODEL_DIR):\n",
    "        self.model.load_state_dict(torch.load(directory / filename))\n",
    "    \n",
    "    def train(self, num_epochs, patience=np.inf, leave_pbar=True):\n",
    "        best_loss = np.inf\n",
    "        best_epoch = 0\n",
    "        best_model = None\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            tstats = stats(self.batch_size)\n",
    "            vstats = stats(self.batch_size)\n",
    "            \n",
    "            ## TRAINING LOOP\n",
    "            pbar_train = tqdm(self.train_loader, total=len(self.train_loader), leave=False)\n",
    "            self.model.train()\n",
    "            for idx, (text, targets) in enumerate(pbar_train):\n",
    "                # Move data to device\n",
    "                text = text.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(text)\n",
    "                outputs = outputs.squeeze(1)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                \n",
    "                # Backpropagation\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Update loss and accuracy\n",
    "                predictions = torch.round(torch.sigmoid(outputs))\n",
    "                tstats.update(loss.item(), (predictions == targets).sum().item())\n",
    "                \n",
    "                # Update progress bar\n",
    "                desc = (\n",
    "                    f\"Epoch {epoch+1:02}/{num_epochs:02}\"\n",
    "                    f\" - Train Loss: {tstats.avg_loss():.4f}\"\n",
    "                    f\" - Train Acc: {tstats.avg_acc():.4f}\"\n",
    "                )\n",
    "                pbar_train.set_description(desc=desc)\n",
    "            \n",
    "            ## VALIDATION LOOP  \n",
    "            pbar_val = tqdm(self.val_loader, total=len(self.val_loader), leave=leave_pbar)\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for idx, (text, targets) in enumerate(pbar_val):\n",
    "                    # Move data to device\n",
    "                    text = text.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = self.model(text)\n",
    "                    outputs = outputs.squeeze(1)\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                    \n",
    "                    # Update loss and accuracy\n",
    "                    predictions = torch.round(torch.sigmoid(outputs))\n",
    "                    vstats.update(loss.item(), (predictions == targets).sum().item())\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    desc = (\n",
    "                        f\"Epoch {epoch+1:02}/{num_epochs:02}\"\n",
    "                        f\" - Train Loss: {tstats.avg_loss():.4f}\"\n",
    "                        f\" - Train Acc: {tstats.avg_acc():.4f}\"\n",
    "                        f\" - Val Loss: {vstats.avg_loss():.4f}\"\n",
    "                        f\" - Val Acc: {vstats.avg_acc():.4f}\"\n",
    "                    )\n",
    "                    pbar_val.set_description(desc=desc)\n",
    "                          \n",
    "            ## CHECKPOINTING AND EARLY STOPPING\n",
    "            if vstats.avg_loss() < best_loss:\n",
    "                best_loss = vstats.avg_loss()\n",
    "                best_epoch = epoch\n",
    "                best_model = self.model.state_dict()\n",
    "                save_checkpoint(self.model, f\"best_model_{best_epoch}.pt\")\n",
    "                \n",
    "            if epoch - best_epoch > patience:\n",
    "                print(f\"Stopping early at epoch {epoch+1}\")\n",
    "                break\n",
    "                \n",
    "        return best_model\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(DATA_DIR / 'nuclear_energy_en' / 'processed_data.csv')\n",
    "data_df[\"pro_nuclear\"] = data_df[\"pro_nuclear\"].astype(int)\n",
    "# print(f\"Removing {data_df['text'].isna().sum()} rows with NaN values\")\n",
    "data_df = data_df.dropna()\n",
    "# Remove rows that begin with \"##\"\n",
    "data_df = data_df[~data_df['text'].str.startswith('##')]\n",
    "\n",
    "test_split = 0.2\n",
    "val_split = 0.2\n",
    "\n",
    "train_df, test_df = train_test_split(data_df, test_size=test_split, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=val_split/(1-test_split), random_state=42)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased', use_fast=False)\n",
    "\n",
    "# print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    learning_rate=3e-3,\n",
    "    dropout=0.65,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embedding_dim=768,\n",
    "    rnn_size=128,\n",
    "    out_size=1,\n",
    "    rnn_num_layers=2,\n",
    "    bidirectional=False,\n",
    "    batch_first=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, train_dataset = get_loader(train_df, tokenizer=tokenizer, config=config)\n",
    "val_loader, val_dataset = get_loader(val_df, tokenizer=tokenizer, config=config)\n",
    "test_loader, test_dataset = get_loader(test_df, tokenizer=tokenizer, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(config).to(device)\n",
    "# criterion = nn.CrossEntropyLoss(reduction=\"mean\").to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"mean\").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    batch_size=config.batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "    num_epochs=20,\n",
    "    patience=10,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(28996, 768)\n",
       "  (lstm): LSTM(768, 128, num_layers=2, batch_first=True, dropout=0.65)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.65, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "prediction_model = RNN(config).to(device)\n",
    "prediction_model.load_state_dict(torch.load(MODEL_DIR / 'checkpoint.pt'))\n",
    "prediction_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    tokenized_text = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    out = model(tokenized_text)\n",
    "\n",
    "    pred = torch.sigmoid(out)\n",
    "    rounded_pred = torch.round(pred)\n",
    "\n",
    "    return pred, rounded_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.9334 - Pro Nuclear: 1.0\n"
     ]
    }
   ],
   "source": [
    "txt = \"Nuclear energy is necessary to combat climate change.\"\n",
    "\n",
    "pred, rounded_pred = predict(prediction_model, txt)\n",
    "\n",
    "print(f\"Prediction: {pred.item():.4f} - Pro Nuclear: {rounded_pred.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.0823 - Pro Nuclear: 0.0\n"
     ]
    }
   ],
   "source": [
    "txt = \"Nuclear waste is a huge problem.\"\n",
    "\n",
    "pred, rounded_pred = predict(prediction_model, txt)\n",
    "\n",
    "print(f\"Prediction: {pred.item():.4f} - Pro Nuclear: {rounded_pred.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk-nuclear",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

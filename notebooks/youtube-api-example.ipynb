{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YouTube API Info\n",
    "Costs:\n",
    "- Search: 100 credits per request (1-50 videos)\n",
    "- Video Details: 1 credit per request (1-50 videos)\n",
    "- Comment Threads: 1 credit per request (1-100 comment threads)\n",
    "\n",
    "Quota: 10,000 credits per day\n",
    "- Search: max 5,000 videos per day\n",
    "- Video Details: max 500,000 videos per day\n",
    "- Comment Threads: max 1,000,000 comment threads per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib as Path\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# from config import YOUTUBE_API_KEY\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out the YouTube API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- https://developers.google.com/youtube/v3/docs\n",
    "- https://www.thepythoncode.com/article/using-youtube-api-in-python\n",
    "- https://medium.com/daily-python/python-script-to-search-content-using-youtube-data-api-daily-python-8-1084776a6578\n",
    "- https://medium.com/mcd-unison/youtube-data-api-v3-in-python-tutorial-with-examples-e829a25d2ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build(serviceName=API_SERVICE_NAME, version=API_VERSION, developerKey=YOUTUBE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isodate\n",
    "\n",
    "def print_video_infos(video_response):\n",
    "    items = video_response.get(\"items\")[0]\n",
    "    # get the snippet, statistics & content details from the video response\n",
    "    snippet         = items[\"snippet\"]\n",
    "    statistics      = items[\"statistics\"]\n",
    "    content_details = items[\"contentDetails\"]\n",
    "    video_id        = items[\"id\"]\n",
    "    # get infos from the snippet\n",
    "    channel_title = snippet[\"channelTitle\"]\n",
    "    title         = snippet[\"title\"]\n",
    "    description   = snippet[\"description\"]\n",
    "    publish_time  = snippet[\"publishedAt\"]\n",
    "    # get stats infos\n",
    "    comment_count = statistics[\"commentCount\"] if \"commentCount\" in statistics else \"NaN\"\n",
    "    like_count    = statistics[\"likeCount\"] if \"likeCount\" in statistics else \"NaN\"\n",
    "    view_count    = statistics[\"viewCount\"]\n",
    "    # get duration from content details\n",
    "    duration = content_details[\"duration\"]\n",
    "    # duration in the form of something like 'PT5H50M15S'\n",
    "    # parsing it to be something like '5:50:15'\n",
    "    duration_str = isodate.strftime(isodate.parse_duration(duration), \"%H:%M:%S\")\n",
    "    \n",
    "    print(f\"\"\"\\\n",
    "    Title: {title}\n",
    "    Channel Title: {channel_title}\n",
    "    Video ID: {video_id}\n",
    "    Publish time: {publish_time}\n",
    "    Duration: {duration_str}\n",
    "    Number of comments: {comment_count}\n",
    "    Number of likes: {like_count}\n",
    "    Number of views: {view_count}\n",
    "    \"\"\")\n",
    "    \n",
    "    # Description: {description}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 API Credits Per Request/Search\n",
    "# https://developers.google.com/youtube/v3/docs/search/list\n",
    "def search(youtube, **kwargs):\n",
    "    return youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        **kwargs\n",
    "    ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 API Credit Per Request/Video\n",
    "# https://developers.google.com/youtube/v3/docs/videos/list\n",
    "def get_video_details(youtube, **kwargs):\n",
    "    return youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        **kwargs,\n",
    "    ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 API Credit Per Request/Comment Thread\n",
    "# https://developers.google.com/youtube/v3/docs/commentThreads/list\n",
    "def get_video_comment_threads(youtube, get_replies=False, **kwargs):\n",
    "    part = \"snippet\"\n",
    "    part += \",replies\" if get_replies else \"\"\n",
    "    return youtube.commentThreads().list(\n",
    "        part=part,\n",
    "        **kwargs\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for the query 'nuclear' and retrieve 2 items only\n",
    "# https://developers.google.com/youtube/v3/docs/search/list\n",
    "response = search(\n",
    "    youtube,\n",
    "    q=\"StopTheSteal\",\n",
    "    pageToken=None, \n",
    "    publishedAfter=\"2021-01-01T00:00:00Z\",\n",
    "    publishedBefore=\"2021-01-12T00:00:00Z\",\n",
    "    order=\"viewCount\", # date, rating, relevance (default), title, videoCount, viewCount\n",
    "    type=\"video\", # channel, playlist, video\n",
    "    maxResults=50, # 0-50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = response.get(\"items\")\n",
    "nextPageToken = response.get(\"nextPageToken\") if \"nextPageToken\" in response else None\n",
    "video_ids = [item[\"id\"][\"videoId\"] for item in items]\n",
    "video_titles = [item[\"snippet\"][\"title\"] for item in items]\n",
    "channel_ids = [item[\"snippet\"][\"channelId\"] for item in items]\n",
    "channel_titles = [item[\"snippet\"][\"channelTitle\"] for item in items]\n",
    "published_time = [item[\"snippet\"][\"publishedAt\"] for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['video_ids'] = video_ids\n",
    "df['video_titles'] = video_titles\n",
    "df['channel_ids'] = channel_ids\n",
    "df['channel_titles'] = channel_titles\n",
    "df['published_time'] = published_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(youtube, query, start_date, end_date, results_to_get=50):\n",
    "    \"\"\"\n",
    "    Search for videos based on a query term.\n",
    "    API Cost: 100 credits for 50 search results\n",
    "    Documentation: https://developers.google.com/youtube/v3/docs/search/list\n",
    "    \n",
    "    Parameters:\n",
    "        youtube (object): The YouTube API object.\n",
    "        query (str): The search query term.\n",
    "        start_date (str): The start date for the search query.\n",
    "        end_date (str): The end date for the search query.\n",
    "        max_results (int): The maximum number of results to return.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame containing the search results.\n",
    "    \"\"\"\n",
    "    nextPageToken = None\n",
    "    first_page = True    \n",
    "    \n",
    "    search_df = pd.DataFrame()\n",
    "    while (nextPageToken is not None) or (first_page is True):\n",
    "        first_page = False\n",
    "        to_get = 0\n",
    "        if results_to_get >= 50:\n",
    "            to_get = 50\n",
    "            results_to_get -= 50\n",
    "        elif 0 < results_to_get < 50:\n",
    "            to_get = results_to_get\n",
    "            results_to_get = 0\n",
    "        else: # results_to_get <= 0\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = youtube.search().list(\n",
    "                part=\"snippet\",\n",
    "                q=query,\n",
    "                pageToken=None,\n",
    "                type=\"video\",\n",
    "                order=\"viewCount\", # date, rating, relevance (default), title, videoCount, viewCount\n",
    "                publishedAfter=start_date + \"T00:00:00Z\",\n",
    "                publishedBefore=end_date + \"T00:00:00Z\",\n",
    "                maxResults=to_get,\n",
    "            ).execute()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "        nextPageToken = response.get(\"nextPageToken\") if \"nextPageToken\" in response else None\n",
    "\n",
    "        items = response.get(\"items\")\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df['video_ids'] = [item[\"id\"][\"videoId\"] for item in items]\n",
    "        df['video_titles'] = [item[\"snippet\"][\"title\"] for item in items]\n",
    "        df['channel_ids'] = [item[\"snippet\"][\"channelId\"] for item in items]\n",
    "        df['channel_titles'] = [item[\"snippet\"][\"channelTitle\"] for item in items]\n",
    "        df['published_time'] = [item[\"snippet\"][\"publishedAt\"] for item in items]\n",
    "    \n",
    "        search_df = pd.concat([search_df, df], ignore_index=True)\n",
    "    \n",
    "    return search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_search_results(youtube, \"StopTheSteal\", \"2021-01-01\", \"2021-01-12\", 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_responses = []\n",
    "# for video_id in video_ids:\n",
    "#     # get the video details\n",
    "#     video_response = get_video_details(youtube, id=video_id)\n",
    "#     video_responses.append(video_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 100 comments from page 0\n"
     ]
    }
   ],
   "source": [
    "comments = []\n",
    "video_id = video_ids[1]\n",
    "\n",
    "next_page_token = None\n",
    "first_page = True\n",
    "page_num = 0\n",
    "max_pages = 1\n",
    "\n",
    "while (next_page_token is not None) or (first_page is True):\n",
    "    first_page = False\n",
    "    if page_num >= max_pages:\n",
    "        break\n",
    "    \n",
    "    threads = get_video_comment_threads(\n",
    "        youtube,\n",
    "        videoId=video_id,\n",
    "        get_replies=True,\n",
    "        pageToken=next_page_token,\n",
    "        order=\"time\", # time, relevance (sorting by relevance uses an algorithm which can filter out some comments)\n",
    "        maxResults=100,\n",
    "        )\n",
    "    \n",
    "    next_page_token = threads.get(\"nextPageToken\") if \"nextPageToken\" in threads else None\n",
    "    \n",
    "    comments += threads['items']\n",
    "    \n",
    "    print(f\"Retrieved {len(threads['items'])} comments from page {page_num}\")\n",
    "    page_num += 1\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_comments = []\n",
    "for comment in comments:\n",
    "    flattened_comments += [comment[\"snippet\"][\"topLevelComment\"]]\n",
    "    if \"replies\" in comment:\n",
    "        flattened_comments += comment[\"replies\"][\"comments\"]\n",
    "\n",
    "flattened_df = pd.json_normalize(flattened_comments, sep=\".\")\n",
    "\n",
    "flattened_df = flattened_df.rename(\n",
    "    columns={\n",
    "        \"snippet.videoId\" : \"video_id\",\n",
    "        \"snippet.textOriginal\" : \"text_original\",\n",
    "        \"snippet.authorDisplayName\" : \"author_display_name\",\n",
    "        \"snippet.authorChannelId.value\" : \"author_channel_id\",\n",
    "        \"snippet.likeCount\" : \"like_count\",\n",
    "        \"snippet.publishedAt\" : \"published_at\",\n",
    "        \"snippet.updatedAt\" : \"updated_at\",\n",
    "        \"snippet.parentId\" : \"parent_id\",\n",
    "    }\n",
    ")\n",
    "\n",
    "flattened_df = flattened_df[\n",
    "    [\"id\",\n",
    "    \"video_id\",\n",
    "    \"text_original\",\n",
    "    \"author_display_name\",\n",
    "    \"author_channel_id\",\n",
    "    \"like_count\",\n",
    "    \"published_at\",\n",
    "    \"updated_at\",\n",
    "    \"parent_id\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>text_original</th>\n",
       "      <th>author_display_name</th>\n",
       "      <th>author_channel_id</th>\n",
       "      <th>like_count</th>\n",
       "      <th>published_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>This is what it was like to be inside the Capi...</td>\n",
       "      <td>VICE News</td>\n",
       "      <td>UCZaT_X_mc0BI-djXOlfhqWQ</td>\n",
       "      <td>295</td>\n",
       "      <td>2021-01-11T23:19:38Z</td>\n",
       "      <td>2021-01-11T23:19:38Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9nLM0qjNUTG</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>Feds caught destroying evidence on Jan 6 trial...</td>\n",
       "      <td>Rob Howell</td>\n",
       "      <td>UCyE10gQA3fBXp2ITp3xhc2g</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-17T02:04:04Z</td>\n",
       "      <td>2023-03-17T02:04:04Z</td>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9jldUie-Mkk</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>@GhostsAmongUs üëàüèºüòè the only group that hasn't ...</td>\n",
       "      <td>NVMVNV</td>\n",
       "      <td>UCPvb48QraVqqx0J3ZpW2Wlg</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-18T06:19:21Z</td>\n",
       "      <td>2022-12-18T06:19:21Z</td>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9jldMLJQeDo</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>@GhostsAmongUs üëàüèºüòè name a race that hasn't act...</td>\n",
       "      <td>NVMVNV</td>\n",
       "      <td>UCPvb48QraVqqx0J3ZpW2Wlg</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-18T06:18:12Z</td>\n",
       "      <td>2022-12-18T06:18:12Z</td>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9jldEqqyVE-</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>@Jesse Morin  üëàüèºüôÑ there's a difference between...</td>\n",
       "      <td>NVMVNV</td>\n",
       "      <td>UCPvb48QraVqqx0J3ZpW2Wlg</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-18T06:17:11Z</td>\n",
       "      <td>2022-12-18T06:17:11Z</td>\n",
       "      <td>UgxBtRRdCCHG55EkHUZ4AaABAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>UgwKg0s3Me18_EZM0w54AaABAg</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>That day of violence followed a whole summer o...</td>\n",
       "      <td>Mark Cole</td>\n",
       "      <td>UCOiLgQ0lrrZxIvu8GrvTP1Q</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-24T15:38:20Z</td>\n",
       "      <td>2022-12-24T15:38:20Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Ugzhk8ttMDvJB6zWXhF4AaABAg</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>Antifa was payed to get this sarted</td>\n",
       "      <td>Mark Cole</td>\n",
       "      <td>UCOiLgQ0lrrZxIvu8GrvTP1Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-24T15:35:07Z</td>\n",
       "      <td>2022-12-24T15:35:07Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Ugzuh4iISUl7Ow12GSl4AaABAg</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>Why aren't you guys questioning Nancy Pelosi's...</td>\n",
       "      <td>Gaming History Source</td>\n",
       "      <td>UCgeSfaLXS8Macm3ddzYF_wg</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-23T17:44:32Z</td>\n",
       "      <td>2022-12-23T17:44:32Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>UgysPp9EU9qo2wCEsCt4AaABAg</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>So sad so many people went to jail for Trump p...</td>\n",
       "      <td>Kym Jess</td>\n",
       "      <td>UCiSaQ4cEACXj3Wd5fymDAuA</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-22T18:13:26Z</td>\n",
       "      <td>2022-12-22T18:13:26Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>UgysPp9EU9qo2wCEsCt4AaABAg.9jxDONB8Uj79k_vBP65iO1</td>\n",
       "      <td>lfP_5L8epow</td>\n",
       "      <td>Meanwhile all you've done with your life is ?</td>\n",
       "      <td>Mynamedoesntmatter</td>\n",
       "      <td>UCmWH1K9q85qIdWADyrgjMaQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-07T13:34:30Z</td>\n",
       "      <td>2023-01-07T13:34:30Z</td>\n",
       "      <td>UgysPp9EU9qo2wCEsCt4AaABAg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id     video_id  \\\n",
       "0                           UgxBtRRdCCHG55EkHUZ4AaABAg  lfP_5L8epow   \n",
       "1    UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9nLM0qjNUTG  lfP_5L8epow   \n",
       "2    UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9jldUie-Mkk  lfP_5L8epow   \n",
       "3    UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9jldMLJQeDo  lfP_5L8epow   \n",
       "4    UgxBtRRdCCHG55EkHUZ4AaABAg.9IO_1krp-WF9jldEqqyVE-  lfP_5L8epow   \n",
       "..                                                 ...          ...   \n",
       "110                         UgwKg0s3Me18_EZM0w54AaABAg  lfP_5L8epow   \n",
       "111                         Ugzhk8ttMDvJB6zWXhF4AaABAg  lfP_5L8epow   \n",
       "112                         Ugzuh4iISUl7Ow12GSl4AaABAg  lfP_5L8epow   \n",
       "113                         UgysPp9EU9qo2wCEsCt4AaABAg  lfP_5L8epow   \n",
       "114  UgysPp9EU9qo2wCEsCt4AaABAg.9jxDONB8Uj79k_vBP65iO1  lfP_5L8epow   \n",
       "\n",
       "                                         text_original    author_display_name  \\\n",
       "0    This is what it was like to be inside the Capi...              VICE News   \n",
       "1    Feds caught destroying evidence on Jan 6 trial...             Rob Howell   \n",
       "2    @GhostsAmongUs üëàüèºüòè the only group that hasn't ...                 NVMVNV   \n",
       "3    @GhostsAmongUs üëàüèºüòè name a race that hasn't act...                 NVMVNV   \n",
       "4    @Jesse Morin  üëàüèºüôÑ there's a difference between...                 NVMVNV   \n",
       "..                                                 ...                    ...   \n",
       "110  That day of violence followed a whole summer o...              Mark Cole   \n",
       "111                Antifa was payed to get this sarted              Mark Cole   \n",
       "112  Why aren't you guys questioning Nancy Pelosi's...  Gaming History Source   \n",
       "113  So sad so many people went to jail for Trump p...               Kym Jess   \n",
       "114      Meanwhile all you've done with your life is ?     Mynamedoesntmatter   \n",
       "\n",
       "            author_channel_id  like_count          published_at  \\\n",
       "0    UCZaT_X_mc0BI-djXOlfhqWQ         295  2021-01-11T23:19:38Z   \n",
       "1    UCyE10gQA3fBXp2ITp3xhc2g           0  2023-03-17T02:04:04Z   \n",
       "2    UCPvb48QraVqqx0J3ZpW2Wlg           0  2022-12-18T06:19:21Z   \n",
       "3    UCPvb48QraVqqx0J3ZpW2Wlg           0  2022-12-18T06:18:12Z   \n",
       "4    UCPvb48QraVqqx0J3ZpW2Wlg           0  2022-12-18T06:17:11Z   \n",
       "..                        ...         ...                   ...   \n",
       "110  UCOiLgQ0lrrZxIvu8GrvTP1Q           1  2022-12-24T15:38:20Z   \n",
       "111  UCOiLgQ0lrrZxIvu8GrvTP1Q           0  2022-12-24T15:35:07Z   \n",
       "112  UCgeSfaLXS8Macm3ddzYF_wg           1  2022-12-23T17:44:32Z   \n",
       "113  UCiSaQ4cEACXj3Wd5fymDAuA           0  2022-12-22T18:13:26Z   \n",
       "114  UCmWH1K9q85qIdWADyrgjMaQ           0  2023-01-07T13:34:30Z   \n",
       "\n",
       "               updated_at                   parent_id  \n",
       "0    2021-01-11T23:19:38Z                         NaN  \n",
       "1    2023-03-17T02:04:04Z  UgxBtRRdCCHG55EkHUZ4AaABAg  \n",
       "2    2022-12-18T06:19:21Z  UgxBtRRdCCHG55EkHUZ4AaABAg  \n",
       "3    2022-12-18T06:18:12Z  UgxBtRRdCCHG55EkHUZ4AaABAg  \n",
       "4    2022-12-18T06:17:11Z  UgxBtRRdCCHG55EkHUZ4AaABAg  \n",
       "..                    ...                         ...  \n",
       "110  2022-12-24T15:38:20Z                         NaN  \n",
       "111  2022-12-24T15:35:07Z                         NaN  \n",
       "112  2022-12-23T17:44:32Z                         NaN  \n",
       "113  2022-12-22T18:13:26Z                         NaN  \n",
       "114  2023-01-07T13:34:30Z  UgysPp9EU9qo2wCEsCt4AaABAg  \n",
       "\n",
       "[115 rows x 9 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk-nuclear",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3120d9f87eabf5535f44bfda2bf17334ee7ee4298f68d473c9683e2ad61a73ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
